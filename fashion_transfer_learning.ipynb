{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from utils import load_data, data_split_fashion, FashionDataset, get_dataloaders\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, Normalize\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './fashion_full_upd/'\n",
    "dataloader_params = {'batch_size': 1,\n",
    "                     'shuffle': True,\n",
    "                     'num_workers': 8}\n",
    "resize_normalize_transform = Compose([Resize((224, 224)), ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "val_split = 0.2\n",
    "num_epochs = 30\n",
    "\n",
    "styles_df = load_data(data_path)\n",
    "dataloaders = get_dataloaders(data_path, val_split, resize_normalize_transform, dataloader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# classes are weighted in proportion to their frequency to ameliorate the severe class imbalance\n",
    "sorted_class_counts = np.array(styles_df.groupby(['articleType']).size().sort_values(ascending=False))\n",
    "class_weights = sorted_class_counts / np.sum(sorted_class_counts)\n",
    "class_weights = torch.tensor(class_weights,  dtype=torch.float)\n",
    "if use_cuda:\n",
    "    class_weights = class_weights.cuda()\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "# reinitialize the fc layer\n",
    "model.fc = nn.Linear(model.fc.in_features, len(class_weights))\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "    \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(dataloader, model, criterion, use_cuda):\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloader):\n",
    "            if use_cuda:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss\n",
    "\n",
    "def train(dataloader_train, dataloader_val, n_epochs, model, criterion, optimizer, use_cuda):\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "        train_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['others_val']):\n",
    "            print(i)\n",
    "            if use_cuda:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss = train_loss / len(dataloader_train.dataset)\n",
    "        val_loss = compute_loss(dataloader_val, model, criterion, use_cuda) / len(dataloader_val.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print('Epoch {}: train loss {}, val loss {}'.format(epoch + 1, train_loss, val_loss))\n",
    "    return train_losses, val_losses, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, model = train(dataloaders['top20_train'], \n",
    "                                        dataloaders['top20_val'], \n",
    "                                        num_epochs, \n",
    "                                        model, \n",
    "                                        criterion, \n",
    "                                        optimizer, \n",
    "                                        use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
